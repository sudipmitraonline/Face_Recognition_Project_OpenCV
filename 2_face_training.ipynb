{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this second phase, we must take all user data from our dataset and “trainer” the OpenCV Recognizer. This is done directly by a specific OpenCV function. The result will be a .yml file that will be saved on a “trainer/” directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUDIP MITRA's AI DEVELOPMENT LAB\n",
    "sudipmitraonline@gmail.com\n",
    "\n",
    "github.com/sudipmitraonline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"ok te s t u ht ai ic\" width=\"680\" height=\"367\" srcset=\"https://miro.medium.com/max/552/0*N4IcbE8v2nwgj6Xg. 276w, https://miro.medium.com/max/1104/0*N4IcbE8v2nwgj6Xg. 552w, https://miro.medium.com/max/1280/0*N4IcbE8v2nwgj6Xg. 640w, https://miro.medium.com/max/1360/0*N4IcbE8v2nwgj6Xg. 680w\" sizes=\"680px\" role=\"presentation\" src=\"https://miro.medium.com/max/850/0*N4IcbE8v2nwgj6Xg.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let’s start creating a subdirectory where we will store the trained data: mkdir trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "#@Author : Sudip Mitra\n",
    "#sudipmitraonline@gmail.com\n",
    "#github.com/sudipmitraonline\n",
    "\n",
    "# Path for face image database\n",
    "path = 'dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') \n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
